{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch로 시작하는 딥러닝 입문\n",
    "\n",
    "## 2장 : Linear Regression\n",
    "\n",
    "https://wikidocs.net/60036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-4 Class Implementation\n",
    "\n",
    "이전 장에서는 단순선형회귀 모델을 library를 사용하여 구현하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 class로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 3.235710\n",
      "Epoch  100/2000 Cost: 0.117913\n",
      "Epoch  200/2000 Cost: 0.072863\n",
      "Epoch  300/2000 Cost: 0.045025\n",
      "Epoch  400/2000 Cost: 0.027823\n",
      "Epoch  500/2000 Cost: 0.017193\n",
      "Epoch  600/2000 Cost: 0.010624\n",
      "Epoch  700/2000 Cost: 0.006565\n",
      "Epoch  800/2000 Cost: 0.004057\n",
      "Epoch  900/2000 Cost: 0.002507\n",
      "Epoch 1000/2000 Cost: 0.001549\n",
      "Epoch 1100/2000 Cost: 0.000957\n",
      "Epoch 1200/2000 Cost: 0.000592\n",
      "Epoch 1300/2000 Cost: 0.000366\n",
      "Epoch 1400/2000 Cost: 0.000226\n",
      "Epoch 1500/2000 Cost: 0.000140\n",
      "Epoch 1600/2000 Cost: 0.000086\n",
      "Epoch 1700/2000 Cost: 0.000053\n",
      "Epoch 1800/2000 Cost: 0.000033\n",
      "Epoch 1900/2000 Cost: 0.000020\n",
      "Epoch 2000/2000 Cost: 0.000013\n"
     ]
    }
   ],
   "source": [
    "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward() # backward 연산\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.9959]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0093], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 30255.337891\n",
      "Epoch  100/2000 Cost: 10.199368\n",
      "Epoch  200/2000 Cost: 9.670970\n",
      "Epoch  300/2000 Cost: 9.170458\n",
      "Epoch  400/2000 Cost: 8.696280\n",
      "Epoch  500/2000 Cost: 8.247166\n",
      "Epoch  600/2000 Cost: 7.821729\n",
      "Epoch  700/2000 Cost: 7.418700\n",
      "Epoch  800/2000 Cost: 7.036956\n",
      "Epoch  900/2000 Cost: 6.675336\n",
      "Epoch 1000/2000 Cost: 6.332810\n",
      "Epoch 1100/2000 Cost: 6.008299\n",
      "Epoch 1200/2000 Cost: 5.700940\n",
      "Epoch 1300/2000 Cost: 5.409776\n",
      "Epoch 1400/2000 Cost: 5.133981\n",
      "Epoch 1500/2000 Cost: 4.872685\n",
      "Epoch 1600/2000 Cost: 4.625251\n",
      "Epoch 1700/2000 Cost: 4.390803\n",
      "Epoch 1800/2000 Cost: 4.168709\n",
      "Epoch 1900/2000 Cost: 3.958354\n",
      "Epoch 2000/2000 Cost: 3.759071\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-5 Mini Batch and Data Load\n",
    "\n",
    "이번 장에서는 데이터를 로드하는 방법과 미니 배치 경사 하강법에 대해 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch and Batch Size\n",
    "\n",
    "데이터의 샘플 개수는 5개입니다. 전체 데이터를 하나의 행렬로 선언하여 전체 데이터에 대해서 경사 하강법을 수행하여 학습할 수 있습니다. 그러나 데이터의 개수가 많으면 경사 하강법을 수행하는 것은 매우 느릴 뿐만 아니라 많은 계산이 필요하기에 전체 데이터를 더 적은 단위로 나누어서 해당 단위로 학습하는 개념이 바로 'Mini Batch'입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration\n",
    "\n",
    "![](https://wikidocs.net/images/page/36033/batchandepochiteration.PNG)\n",
    "\n",
    "위의 그림은 epoch와 iteration의 관계를 보여줍니다.\n",
    "\n",
    "iteration은 한 번의 epoch 내에서 이루어지는 W와 b의 업데이트 횟수입니다. 전체 데이터가 2000개일 때 배치 크기를 200으로 한다면 iteration의 총 개수는 10개이며, 이는 한번의 epoch 당 매개 변수 업데이트가 총 10번이 이루어짐을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 25669.121094\n",
      "Epoch    0/20 Batch 2/3 Cost: 11589.047852\n",
      "Epoch    0/20 Batch 3/3 Cost: 1572.551025\n",
      "Epoch    1/20 Batch 1/3 Cost: 987.094849\n",
      "Epoch    1/20 Batch 2/3 Cost: 345.370544\n",
      "Epoch    1/20 Batch 3/3 Cost: 112.507042\n",
      "Epoch    2/20 Batch 1/3 Cost: 37.316460\n",
      "Epoch    2/20 Batch 2/3 Cost: 15.557783\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.288372\n",
      "Epoch    3/20 Batch 1/3 Cost: 9.087434\n",
      "Epoch    3/20 Batch 2/3 Cost: 4.532706\n",
      "Epoch    3/20 Batch 3/3 Cost: 4.698104\n",
      "Epoch    4/20 Batch 1/3 Cost: 7.589594\n",
      "Epoch    4/20 Batch 2/3 Cost: 3.975832\n",
      "Epoch    4/20 Batch 3/3 Cost: 5.150841\n",
      "Epoch    5/20 Batch 1/3 Cost: 5.165402\n",
      "Epoch    5/20 Batch 2/3 Cost: 6.083657\n",
      "Epoch    5/20 Batch 3/3 Cost: 5.436021\n",
      "Epoch    6/20 Batch 1/3 Cost: 5.072534\n",
      "Epoch    6/20 Batch 2/3 Cost: 7.467512\n",
      "Epoch    6/20 Batch 3/3 Cost: 1.840523\n",
      "Epoch    7/20 Batch 1/3 Cost: 6.919503\n",
      "Epoch    7/20 Batch 2/3 Cost: 3.790645\n",
      "Epoch    7/20 Batch 3/3 Cost: 5.449834\n",
      "Epoch    8/20 Batch 1/3 Cost: 5.039405\n",
      "Epoch    8/20 Batch 2/3 Cost: 5.984152\n",
      "Epoch    8/20 Batch 3/3 Cost: 5.372385\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.257086\n",
      "Epoch    9/20 Batch 2/3 Cost: 6.587579\n",
      "Epoch    9/20 Batch 3/3 Cost: 12.340636\n",
      "Epoch   10/20 Batch 1/3 Cost: 6.588222\n",
      "Epoch   10/20 Batch 2/3 Cost: 6.147615\n",
      "Epoch   10/20 Batch 3/3 Cost: 5.012909\n",
      "Epoch   11/20 Batch 1/3 Cost: 4.019611\n",
      "Epoch   11/20 Batch 2/3 Cost: 7.229200\n",
      "Epoch   11/20 Batch 3/3 Cost: 4.075795\n",
      "Epoch   12/20 Batch 1/3 Cost: 2.303613\n",
      "Epoch   12/20 Batch 2/3 Cost: 12.959002\n",
      "Epoch   12/20 Batch 3/3 Cost: 3.722752\n",
      "Epoch   13/20 Batch 1/3 Cost: 0.918640\n",
      "Epoch   13/20 Batch 2/3 Cost: 8.234212\n",
      "Epoch   13/20 Batch 3/3 Cost: 7.585008\n",
      "Epoch   14/20 Batch 1/3 Cost: 5.608812\n",
      "Epoch   14/20 Batch 2/3 Cost: 3.418188\n",
      "Epoch   14/20 Batch 3/3 Cost: 7.311092\n",
      "Epoch   15/20 Batch 1/3 Cost: 6.496853\n",
      "Epoch   15/20 Batch 2/3 Cost: 3.110215\n",
      "Epoch   15/20 Batch 3/3 Cost: 9.820634\n",
      "Epoch   16/20 Batch 1/3 Cost: 7.151793\n",
      "Epoch   16/20 Batch 2/3 Cost: 3.354904\n",
      "Epoch   16/20 Batch 3/3 Cost: 3.732297\n",
      "Epoch   17/20 Batch 1/3 Cost: 6.369378\n",
      "Epoch   17/20 Batch 2/3 Cost: 3.589681\n",
      "Epoch   17/20 Batch 3/3 Cost: 5.572628\n",
      "Epoch   18/20 Batch 1/3 Cost: 7.993684\n",
      "Epoch   18/20 Batch 2/3 Cost: 4.051431\n",
      "Epoch   18/20 Batch 3/3 Cost: 1.897345\n",
      "Epoch   19/20 Batch 1/3 Cost: 5.726354\n",
      "Epoch   19/20 Batch 2/3 Cost: 6.095624\n",
      "Epoch   19/20 Batch 3/3 Cost: 2.017652\n",
      "Epoch   20/20 Batch 1/3 Cost: 1.474059\n",
      "Epoch   20/20 Batch 2/3 Cost: 13.985815\n",
      "Epoch   20/20 Batch 3/3 Cost: 3.276754\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        # print(batch_idx)\n",
    "        # print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "            cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.8058]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-6 Custom Dataset\n",
    "\n",
    "Custom Dataset을 만들 때 필요한 뼈대는 다음과 같습니다.\n",
    "- __init__(self)\n",
    "- __len__(self)\n",
    "- __getitem__(self,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self):\n",
    "    #데이터셋의 전처리를 해주는 부분\n",
    "\n",
    "    def __len__(self):\n",
    "    #데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "    #데이터셋에서 특정 1개의 샘플을 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "    def __len__(self): \n",
    "        return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx): \n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 54910.296875\n",
      "Epoch    0/20 Batch 2/3 Cost: 17123.638672\n",
      "Epoch    0/20 Batch 3/3 Cost: 6263.274902\n",
      "Epoch    1/20 Batch 1/3 Cost: 1475.178589\n",
      "Epoch    1/20 Batch 2/3 Cost: 739.200256\n",
      "Epoch    1/20 Batch 3/3 Cost: 54.084068\n",
      "Epoch    2/20 Batch 1/3 Cost: 41.328583\n",
      "Epoch    2/20 Batch 2/3 Cost: 37.951141\n",
      "Epoch    2/20 Batch 3/3 Cost: 30.595739\n",
      "Epoch    3/20 Batch 1/3 Cost: 4.381040\n",
      "Epoch    3/20 Batch 2/3 Cost: 8.683412\n",
      "Epoch    3/20 Batch 3/3 Cost: 3.241110\n",
      "Epoch    4/20 Batch 1/3 Cost: 8.190666\n",
      "Epoch    4/20 Batch 2/3 Cost: 5.888869\n",
      "Epoch    4/20 Batch 3/3 Cost: 2.526730\n",
      "Epoch    5/20 Batch 1/3 Cost: 5.523765\n",
      "Epoch    5/20 Batch 2/3 Cost: 3.203250\n",
      "Epoch    5/20 Batch 3/3 Cost: 17.217131\n",
      "Epoch    6/20 Batch 1/3 Cost: 6.739715\n",
      "Epoch    6/20 Batch 2/3 Cost: 4.840462\n",
      "Epoch    6/20 Batch 3/3 Cost: 11.832987\n",
      "Epoch    7/20 Batch 1/3 Cost: 9.487991\n",
      "Epoch    7/20 Batch 2/3 Cost: 4.223427\n",
      "Epoch    7/20 Batch 3/3 Cost: 10.913296\n",
      "Epoch    8/20 Batch 1/3 Cost: 11.016167\n",
      "Epoch    8/20 Batch 2/3 Cost: 9.552896\n",
      "Epoch    8/20 Batch 3/3 Cost: 6.418896\n",
      "Epoch    9/20 Batch 1/3 Cost: 4.210768\n",
      "Epoch    9/20 Batch 2/3 Cost: 4.295463\n",
      "Epoch    9/20 Batch 3/3 Cost: 15.862358\n",
      "Epoch   10/20 Batch 1/3 Cost: 7.379895\n",
      "Epoch   10/20 Batch 2/3 Cost: 4.645247\n",
      "Epoch   10/20 Batch 3/3 Cost: 11.549585\n",
      "Epoch   11/20 Batch 1/3 Cost: 6.592645\n",
      "Epoch   11/20 Batch 2/3 Cost: 5.586020\n",
      "Epoch   11/20 Batch 3/3 Cost: 13.494434\n",
      "Epoch   12/20 Batch 1/3 Cost: 6.514342\n",
      "Epoch   12/20 Batch 2/3 Cost: 5.887089\n",
      "Epoch   12/20 Batch 3/3 Cost: 11.788623\n",
      "Epoch   13/20 Batch 1/3 Cost: 7.203542\n",
      "Epoch   13/20 Batch 2/3 Cost: 3.753460\n",
      "Epoch   13/20 Batch 3/3 Cost: 8.884286\n",
      "Epoch   14/20 Batch 1/3 Cost: 7.527767\n",
      "Epoch   14/20 Batch 2/3 Cost: 4.000125\n",
      "Epoch   14/20 Batch 3/3 Cost: 10.979936\n",
      "Epoch   15/20 Batch 1/3 Cost: 4.150759\n",
      "Epoch   15/20 Batch 2/3 Cost: 6.277162\n",
      "Epoch   15/20 Batch 3/3 Cost: 8.309200\n",
      "Epoch   16/20 Batch 1/3 Cost: 4.752577\n",
      "Epoch   16/20 Batch 2/3 Cost: 6.976105\n",
      "Epoch   16/20 Batch 3/3 Cost: 6.412712\n",
      "Epoch   17/20 Batch 1/3 Cost: 8.266171\n",
      "Epoch   17/20 Batch 2/3 Cost: 3.257143\n",
      "Epoch   17/20 Batch 3/3 Cost: 11.680945\n",
      "Epoch   18/20 Batch 1/3 Cost: 5.735023\n",
      "Epoch   18/20 Batch 2/3 Cost: 6.254066\n",
      "Epoch   18/20 Batch 3/3 Cost: 4.902086\n",
      "Epoch   19/20 Batch 1/3 Cost: 6.157449\n",
      "Epoch   19/20 Batch 2/3 Cost: 1.543696\n",
      "Epoch   19/20 Batch 3/3 Cost: 16.291599\n",
      "Epoch   20/20 Batch 1/3 Cost: 4.706262\n",
      "Epoch   20/20 Batch 2/3 Cost: 10.894975\n",
      "Epoch   20/20 Batch 3/3 Cost: 9.975211\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        # print(batch_idx)\n",
    "        # print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "            cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[154.0621]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
